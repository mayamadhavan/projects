{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import NMF, TruncatedSVD\n",
    "from sklearn.cluster import KMeans, DBSCAN, SpectralClustering, MeanShift\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# from itertools import cycle\n",
    "# from sklearn import datasets\n",
    "# import logging\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.metrics import silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class clustering_pipeline:\n",
    "    def __init__(self, vectorizer, n_components, reducer):\n",
    "        self.vectorizer = vectorizer\n",
    "        self.n_dim = n_components\n",
    "        self.reducer = reducer(n_components)\n",
    "        \n",
    "    def fit(self, text):\n",
    "        self.vectorizer.fit(text)\n",
    "        self.vector_data = self.vectorizer.fit_transform(text)\n",
    "        self.topic_data = self.reducer.fit_transform(self.vector_data)\n",
    "        self.texts = text\n",
    "\n",
    "    def tsne(self, n_components, perplexity):\n",
    "        tsne = TSNE(n_components = n_components, perplexity = perplexity)\n",
    "        plt.figure(dpi=300)\n",
    "        vector_tsne = tsne.fit_transform(self.topic_data)\n",
    "        plt.scatter(vector_tsne[:, 0], vector_tsne[:, 1],c=self.labels_, alpha=0.5)\n",
    "        plt.title(f'tSNE on topic space using {self.cluster_method}');\n",
    "        plt.figure(dpi=300)\n",
    "        plt.hist(self.labels_, bins=self.n_clusters);\n",
    "        \n",
    "    def kmeans(self, n_clusters):\n",
    "        self.km = KMeans(n_clusters=n_clusters)\n",
    "        self.labels_ = self.km.fit_predict(self.topic_data)\n",
    "        self.cluster_method='kmeans'\n",
    "        self.n_clusters=n_clusters\n",
    "        self.cluster_centers=self.km.cluster_centers_\n",
    "        \n",
    "    def db(self, eps, min_samples):\n",
    "        self.db = DBSCAN(eps=eps, min_samples=min_samples).fit(self.x)\n",
    "        core_samples_mask = np.zeros_like(self.db.labels_, dtype=bool)\n",
    "        core_samples_mask[self.db.core_sample_indices_] = True\n",
    "        self.labels_ = self.db.labels_\n",
    "        self.cluster_method='db'\n",
    "        n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "        self.n_clusters=n_clusters\n",
    "\n",
    "    def spectral(self, article, num_to_return, n_clusters):\n",
    "        self.sc = SpectralClustering(n_clusters=n_clusters)\n",
    "        self.labels_ = self.sc.fit_predict(self.topic_data)\n",
    "        self.cluster_method='spectral'\n",
    "        self.n_clusters=n_clusters\n",
    "        \n",
    "    def meanshift(self, quantile, n_samples):\n",
    "        bandwidth = estimate_bandwidth(self.x, quantile=quantile, n_samples=n_samples)\n",
    "        self.ms = MeanShift(bandwidth=bandwidth, bin_seeding=True)\n",
    "        self.ms.fit(self.topic_data)\n",
    "        self.labels_ = self.ms.labels_\n",
    "        self.cluster_method = 'meanshift'\n",
    "        self.cluster_centers = self.ms.cluster_centers_\n",
    "\n",
    "        labels_unique = np.unique(self.labels_)\n",
    "        self.n_clusters_ = len(labels_unique)\n",
    "\n",
    "        print(\"number of estimated clusters : %d\" % n_clusters_)\n",
    "\n",
    "        result_texts = [self.texts[i] for i in results[1][0]]\n",
    "        \n",
    "        return result_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(vec1, vec2):\n",
    "    return np.dot(vec1, vec2) / np.sqrt(np.dot(vec1, vec1) * np.dot(vec2, vec2))\n",
    "\n",
    "def best_cluster(cluster):\n",
    "    overall_clusters=[]\n",
    "    for number in set(cluster.labels_):\n",
    "        cluster_center = cluster.km.cluster_centers_[number]\n",
    "        distances=[]\n",
    "        for index, vector in enumerate(cluster.topic_data):\n",
    "            dist = cosine_similarity(cluster_center,vector)\n",
    "            distances.append((dist, index))\n",
    "        distances.sort()\n",
    "        indices=[x[1] for x in distances[-4:]]\n",
    "        print( f\"\\n + {distances[-4:]}\")\n",
    "        for i in indices:\n",
    "            print(\"\\n\" + df.review.iloc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def making_vectorizers(data):\n",
    "    count_vectorizer = CountVectorizer(ngram_range=(1, 2),  \n",
    "                                   stop_words='english', \n",
    "                                   token_pattern=\"\\\\b[a-z][a-z]+\\\\b\",\n",
    "                                   lowercase=True,\n",
    "                                   max_df = 0.6)\n",
    "    tfidf_vectorizer =TfidfVectorizer(ngram_range=(1, 2),  \n",
    "                                   stop_words='english', \n",
    "                                   token_pattern=\"\\\\b[a-z][a-z]+\\\\b\",\n",
    "                                   lowercase=True,\n",
    "                                   max_df = 0.6)\n",
    "    one=clustering_pipeline(count_vectorizer, n_components = 20, reducer = TruncatedSVD)\n",
    "    one.fit(data)\n",
    "    two=clustering_pipeline(tfidf_vectorizer, n_components = 20, reducer = TruncatedSVD)\n",
    "    two.fit(data)\n",
    "    return (one, two)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def many_kmeans(cluster, n_clusters):\n",
    "    for i in range(n_clusters):\n",
    "        cluster.kmeans(i)\n",
    "        best_cluster(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def many_db(cluster, eps, min_samples):\n",
    "    cluster.db(eps, min_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def many_spectral(cluster, article, num_to_return, n_clusters):\n",
    "    for i in range(n_clusters):\n",
    "        cluster.spectral(article, num_to_return, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def many_meanshift(cluster, quantile, n_samples ):\n",
    "    for i in range(n_samples):\n",
    "        cluster.meanshift(quantile, i)\n",
    "        best_cluster(cluster)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
