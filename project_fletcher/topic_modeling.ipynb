{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('final.pkl', 'rb') as f:\n",
    "    df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>eye_color</th>\n",
       "      <th>hair</th>\n",
       "      <th>skin_tone</th>\n",
       "      <th>skin_type</th>\n",
       "      <th>skin_concerns</th>\n",
       "      <th>foundation_color</th>\n",
       "      <th>review</th>\n",
       "      <th>recommend</th>\n",
       "      <th>unhelpful</th>\n",
       "      <th>helpful</th>\n",
       "      <th>star</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>creecreex</td>\n",
       "      <td>Brown</td>\n",
       "      <td>Brunette</td>\n",
       "      <td>Deep</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Cellulite</td>\n",
       "      <td>370</td>\n",
       "      <td>I have 370 and I got matched at Sephora. I lik...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jijine</td>\n",
       "      <td>Brown</td>\n",
       "      <td>Black</td>\n",
       "      <td>Dark</td>\n",
       "      <td>Combination</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>470</td>\n",
       "      <td>It is like my skin but better. very lightweigh...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bloodyblondie</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Black</td>\n",
       "      <td>Porcelain</td>\n",
       "      <td>Dry</td>\n",
       "      <td>Blackheads</td>\n",
       "      <td>100</td>\n",
       "      <td>I was so nervous about trying this product bec...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>miralanani</td>\n",
       "      <td>Brown</td>\n",
       "      <td>Brunette</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Combination</td>\n",
       "      <td>Acne</td>\n",
       "      <td>270</td>\n",
       "      <td>This product was amazing! Just fell in love! T...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>shaaliyah</td>\n",
       "      <td>Brown</td>\n",
       "      <td>Black</td>\n",
       "      <td>Deep</td>\n",
       "      <td>Combination</td>\n",
       "      <td>Acne</td>\n",
       "      <td>370</td>\n",
       "      <td>Since purchasing this foundation it's been my ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        username eye_color      hair  skin_tone    skin_type skin_concerns  \\\n",
       "0      creecreex     Brown  Brunette       Deep       Normal     Cellulite   \n",
       "1         Jijine     Brown     Black       Dark  Combination       Unknown   \n",
       "2  bloodyblondie      Blue     Black  Porcelain          Dry    Blackheads   \n",
       "3     miralanani     Brown  Brunette     Medium  Combination          Acne   \n",
       "4      shaaliyah     Brown     Black       Deep  Combination          Acne   \n",
       "\n",
       "  foundation_color                                             review  \\\n",
       "0              370  I have 370 and I got matched at Sephora. I lik...   \n",
       "1              470  It is like my skin but better. very lightweigh...   \n",
       "2              100  I was so nervous about trying this product bec...   \n",
       "3              270  This product was amazing! Just fell in love! T...   \n",
       "4              370  Since purchasing this foundation it's been my ...   \n",
       "\n",
       "  recommend unhelpful helpful star  \n",
       "0         1         0      14  100  \n",
       "1         1         0       5  100  \n",
       "2         1         0       5  100  \n",
       "3         1         0       5  100  \n",
       "4         1         0      38  100  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count Vectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora, models, similarities, matutils\n",
    "from sklearn import datasets\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "import logging\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words_list=list(ENGLISH_STOP_WORDS.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_words=['coverage', 'foundation', 'fenty', 'finish', 'does', 've', 'doesn', 'look', 'like', 'product', 'don', 'face', 'just', 'really']\n",
    "stop_words_list.extend(new_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer(ngram_range=(1, 2),\n",
    "                                   stop_words=stop_words_list, max_df=0.6, token_pattern=\"\\\\b[a-z][a-z]+\\\\b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_data=count_vectorizer.fit_transform(df['review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_as_array= count_vectorizer.fit_transform(df['review']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt=pd.DataFrame(cv_as_array, columns=count_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2657, 42453)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.6, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 2), preprocessor=None,\n",
       "        stop_words=['besides', 'much', 'someone', 'there', 'anyway', 'wherein', 'on', 'as', 'somewhere', 'empty', 'this', 'why', 'might', 'through', 'amongst', 'could', 'con', 'made', 'we', 'via', 'what', 'forty', 'all', 'here', 'couldnt', 'give', 'had', 'sometimes', 'yet', 'myself', 'too', 'herself', 'unde...fenty', 'finish', 'does', 've', 'doesn', 'look', 'like', 'product', 'don', 'face', 'just', 'really'],\n",
       "        strip_accents=None, token_pattern='\\\\b[a-z][a-z]+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer.fit(df['review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = count_vectorizer.transform(df['review']).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42453, 2657)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = matutils.Sparse2Corpus(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word = { identifier: word for word, identifier in count_vectorizer.vocabulary_.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42453"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(id2word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = models.LdaModel(corpus=corpus, num_topics=5, minimum_probability=0.03, id2word=id2word, passes=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.011*\"dry\" + 0.008*\"love\" + 0.006*\"shade\" + 0.006*\"oily\" + 0.005*\"dry skin\" + 0.005*\"good\" + 0.005*\"matte\" + 0.005*\"looks\" + 0.004*\"use\" + 0.004*\"perfect\"'),\n",
       " (1,\n",
       "  '0.008*\"oily\" + 0.005*\"day\" + 0.005*\"love\" + 0.004*\"matte\" + 0.004*\"work\" + 0.004*\"did\" + 0.004*\"dry\" + 0.004*\"oily skin\" + 0.003*\"shade\" + 0.003*\"looked\"'),\n",
       " (2,\n",
       "  '0.005*\"love\" + 0.004*\"dry\" + 0.004*\"tried\" + 0.004*\"great\" + 0.003*\"looks\" + 0.002*\"shade\" + 0.002*\"use\" + 0.002*\"makeup\" + 0.002*\"day\" + 0.002*\"matte\"'),\n",
       " (3,\n",
       "  '0.009*\"love\" + 0.007*\"color\" + 0.006*\"match\" + 0.006*\"perfect\" + 0.004*\"shade\" + 0.004*\"primer\" + 0.004*\"great\" + 0.004*\"amazing\" + 0.004*\"dry\" + 0.003*\"day\"'),\n",
       " (4,\n",
       "  '0.011*\"love\" + 0.008*\"day\" + 0.004*\"oily\" + 0.004*\"long\" + 0.004*\"matte\" + 0.004*\"powder\" + 0.003*\"great\" + 0.003*\"shade\" + 0.003*\"primer\" + 0.003*\"setting\"')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NMF / SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_topics(model, feature_names, no_top_words, topic_names=None):\n",
    "    for ix, topic in enumerate(model.components_):\n",
    "        if not topic_names or not topic_names[ix]:\n",
    "            print(\"\\nTopic \", ix)\n",
    "        else:\n",
    "            print(\"\\nTopic: '\",topic_names[ix],\"'\")\n",
    "        print(\", \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-no_top_words - 1:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF, TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_comp = 5\n",
    "lsa_tfidf = TruncatedSVD(n_components=n_comp)\n",
    "\n",
    "lsa_tfidf_data = lsa_tfidf.fit_transform(cv_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic  0\n",
      "dry, love, oily, shade, matte, day, primer, color, tried, use\n",
      "\n",
      "Topic  1\n",
      "dry, dry skin, primer, patches, dry patches, use, good, looked, skin dry, work\n",
      "\n",
      "Topic  2\n",
      "love, love love, dry, dry skin, oily, wanted love, oily skin, absolutely love, absolutely, wanted\n",
      "\n",
      "Topic  3\n",
      "oily, oily skin, day, matte, hours, end, foundations, nose, end day, skin oily\n",
      "\n",
      "Topic  4\n",
      "tried, color, looked, primer, did, work, brush, didn, beauty, wanted\n"
     ]
    }
   ],
   "source": [
    "display_topics(lsa_tfidf,count_vectorizer.get_feature_names(),10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
