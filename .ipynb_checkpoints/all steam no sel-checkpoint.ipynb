{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mass Importation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dateutil.parser\n",
    "from datetime import date\n",
    "\n",
    "from pprint import pprint\n",
    "import re\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import os\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import patsy\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "import pickle\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping From Main Steam Search Page\n",
    "Able to Scrape:\n",
    "   1. Game Title (*DataFrame Index*)\n",
    "   2. Systems that the game runs on\n",
    "   3. Release date of game in days\n",
    "   4. Discount by numerical percent\n",
    "   5. Price of Game\n",
    "   6. Number of Reviews (**Dependent Variable**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions\n",
    "Function for parsing date elements in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_date(datestring):\n",
    "    date = dateutil.parser.parse(datestring)\n",
    "    return date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for creating list of links to parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links=['https://store.steampowered.com/search/']\n",
    "for i in range(1,1954):\n",
    "    links.append('https://store.steampowered.com/search/?page='+str(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols = ['title', 'link', 'system', 'systems', 'reviews', 'release_date', 'discount', 'price']\n",
    "# df=pd.DataFrame(columns=cols, index=[])\n",
    "\n",
    "# age=date.today()\n",
    "# for link in links:\n",
    "#     response=requests.get(link)\n",
    "#     soup = BeautifulSoup(response.text, 'html5lib')\n",
    "#     try: \n",
    "#         main_search_table=soup.find('div', id='search_result_container').find_all('div')[1]\n",
    "#     except:\n",
    "#         time.sleep(20)\n",
    "#         main_search_table=soup.find('div', id='search_result_container').find_all('div')[1]\n",
    "#     print(link)\n",
    "#     for game in main_search_table.find_all('a'):\n",
    "#         row={}\n",
    "#         row['title']=game.find('span', class_=\"title\").text #title\n",
    "#         row['link']=game['href'] #link\n",
    "#         systems=[system[\"class\"][1] for system in game.find('p').find_all('span')] #system\n",
    "#         row['system']=len(systems)\n",
    "#         row['systems']=systems\n",
    "#         try:\n",
    "#             row['release_date']=(age-(to_date(game.find('div', class_=\"col search_released responsive_secondrow\").text).date())).days #release date  \n",
    "#         except:\n",
    "#             row['release_date']=0\n",
    "#         for price in game.find_all('div', class_=\"col search_price_discount_combined responsive_secondrow\"): #price and discount\n",
    "#             for discount in price.find_all('div', class_=\"col search_discount responsive_secondrow\"):\n",
    "#                 if discount.find('span'):\n",
    "#                     row['discount']=abs(int(discount.find('span').text.strip('%')))\n",
    "#                     try:\n",
    "#                         row['price']=float(price.find('span', style=\"color: #888888;\").text.strip(\"$\"))\n",
    "#                     except:\n",
    "#                         price = re.sub('[^0-9,.]','', game.find('div', class_=\"col search_price responsive_secondrow\").text).replace(\"\\n\",\"\").strip(\"\\t\")\n",
    "#                         row['price']=price\n",
    "#                 else:\n",
    "#                     row['discount']=0\n",
    "#                     if not game.find('div', class_=\"col search_price responsive_secondrow\").text.replace(\"\\n\",\"\").strip(\"\\t\"):\n",
    "#                         row['price']=0\n",
    "#                     elif game.find('div', class_=\"col search_price responsive_secondrow\").text.replace(\"\\n\",\"\").strip(\"\\t\").lower()[0]!='$': #'free to play' or game.find('div', class_=\"col search_price responsive_secondrow\").text.replace(\"\\n\",\"\").strip(\"\\t\").lower()=='free':\n",
    "#                         row['price']=0\n",
    "#                     else:\n",
    "#                         row['price']=float(game.find('div', class_=\"col search_price responsive_secondrow\").text.replace(\"\\n\",\"\").strip(\"\\t\").strip(\"$\"))  \n",
    "#         for y in game.find_all('div',class_=\"col search_reviewscore responsive_secondrow\"):\n",
    "#             x=[review['data-tooltip-html'] for review in y.find_all('span')]\n",
    "#             if not x:\n",
    "#                 row['reviews']=int(0)\n",
    "#             else:\n",
    "#                 z=x[0].split('<br>')\n",
    "#                 d=z[1].split(\" \")\n",
    "#                 row['reviews']=int(d[3].replace(',', '')) #reviews\n",
    "#         df=df.append(row, ignore_index=True)\n",
    "#         with open('steam_search.pkl', 'wb') as picklefile:\n",
    "#             pickle.dump(df, picklefile)\n",
    "# #     time.sleep(3)\n",
    "    \n",
    "# df.set_index('title', inplace=True)\n",
    "# df.rename(columns=lambda x: x.strip())\n",
    "# pd.options.display.max_rows = 4000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make copy of df from pickle and read into csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"steam_search.pkl\", 'rb') as picklefile: \n",
    "#       df2 = pickle.load(picklefile)\n",
    "# df2.to_csv('steam3.csv')\n",
    "# df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in csv from previous scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('steam3.csv')\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Duplicates (if any)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_dup_df = df[~df.index.duplicated(keep='first')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modifying DataFrame Element Types to Support Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_dup_df['system'] = no_dup_df.system.astype(int)\n",
    "no_dup_df['reviews'] = no_dup_df.reviews.astype(int)\n",
    "no_dup_df['release_date'] = no_dup_df.release_date.astype(int)\n",
    "no_dup_df['discount'] = no_dup_df.discount.astype(int)\n",
    "no_dup_df['price'] = no_dup_df.price.astype(float)\n",
    "no_dup_df['systems'] = no_dup_df.systems.astype(list)\n",
    "#no_dup_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Analysis (IA): DataFrame Resulting From Main Page Scrape \n",
    "### 1. Initial Look at Relationships with Pairplots and Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(no_dup_df, size = 1.2, aspect=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_dup_df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Split into Train/Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=no_dup_df['reviews']\n",
    "X=no_dup_df.drop(['reviews'],1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "traindf=X_train.join(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Run Patsy Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_train, X_train = patsy.dmatrices('reviews ~ system + price + release_date + discount', data=traindf)\n",
    "model = sm.OLS(y_train, X_train)\n",
    "fit = model.fit()\n",
    "fit.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 10 Fold Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "scores = cross_val_score(lr, X_train, y_train, cv=10, scoring='mean_squared_error')\n",
    "print(-scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional Step: Run LassoCV on Initial Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering and General DataFrame Mods\n",
    "\n",
    "### 1. Modify DF to Account for Skew by Logging Reviews; Repeat IA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_dup_df['log_reviews'] = np.log(no_dup_df.reviews + 1)\n",
    "#plt.hist(no_dup_df['log_reviews'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(no_dup_df, size = 1.2, aspect=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_dup_df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=no_dup_df['log_reviews']\n",
    "X=no_dup_df.drop(['log_reviews','reviews'],1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "traindf=X_train.join(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, X_train = patsy.dmatrices('log_reviews ~ system + price + release_date + discount', data=traindf)\n",
    "model = sm.OLS(y_train, X_train)\n",
    "fit = model.fit()\n",
    "fit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "scores = cross_val_score(lr, X_train, y_train, cv=10, scoring='mean_squared_error')\n",
    "print(-scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Seperate Windows/Mac/Linux into Individual Bool 0/1 Columns; Repeat IA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "windows=[1 if 'win' in item else 0 for item in no_dup_df.systems]\n",
    "mac=[1 if 'mac' in item else 0 for item in no_dup_df.systems]\n",
    "linux=[1 if 'linux' in item else 0 for item in no_dup_df.systems]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_dup_df['windows']=pd.Series(windows)\n",
    "no_dup_df['mac']=pd.Series(mac)\n",
    "no_dup_df['linux']=pd.Series(linux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_dup_df['windows'] = no_dup_df.windows.astype(int)\n",
    "no_dup_df['mac'] = no_dup_df.mac.astype(int)\n",
    "no_dup_df['linux'] = no_dup_df.linux.astype(int)\n",
    "#no_dup_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(no_dup_df, size = 1.2, aspect=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_dup_df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=no_dup_df['log_reviews']\n",
    "X=no_dup_df.drop(['log_reviews','reviews'],1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "traindf=X_train.join(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, X_train = patsy.dmatrices('log_reviews ~ system + price + release_date + discount + windows + mac + linux', data=traindf)\n",
    "model = sm.OLS(y_train, X_train)\n",
    "fit = model.fit()\n",
    "fit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "scores = cross_val_score(lr, X_train, y_train, cv=10, scoring='mean_squared_error')\n",
    "print(-scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Drop Movies;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies=[]\n",
    "for i in range(len(no_dup_df['systems'])):\n",
    "    element=(no_dup_df['systems'][i])\n",
    "    if 'win' not in element and 'mac' not in element and 'linux' not in element:\n",
    "        movies.append(1)\n",
    "    else:\n",
    "        movies.append(0)\n",
    "no_dup_df['movies']=movies\n",
    "no_dup_df = no_dup_df[no_dup_df.movies != 1]\n",
    "del(no_dup_df['movies'])\n",
    "no_dup_df.set_index('title', inplace=True)\n",
    "del(no_dup_df['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(no_dup_df, size = 1.2, aspect=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'no_dup_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-3b3df80e93fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mno_dup_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'no_dup_df' is not defined"
     ]
    }
   ],
   "source": [
    "no_dup_df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=no_dup_df['log_reviews']\n",
    "X=no_dup_df.drop(['log_reviews','reviews'],1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "traindf=X_train.join(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, X_train = patsy.dmatrices('log_reviews ~ system + price + release_date + discount + windows + mac + linux', data=traindf)\n",
    "model = sm.OLS(y_train, X_train)\n",
    "fit = model.fit()\n",
    "fit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "scores = cross_val_score(lr, X_train, y_train, cv=10, scoring='mean_squared_error')\n",
    "print(-scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping from Individual Game Pages\n",
    "Available data:\n",
    "    1. Genre\n",
    "    2. Single/Multiplayer\n",
    "    3. Number of Languages\n",
    "    4. Developer\n",
    "    5. Publisher\n",
    "    6. User-defined tages\n",
    "    7. Release date (repeat)\n",
    "    8. Recent Updates\n",
    "    9. System Requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "cols2 = ['title', 'developer', 'user_tags', 'languages', 'genres', 'specs']\n",
    "df_gamepg=pd.DataFrame(columns=cols2, index=[])\n",
    "link_games=list(no_dup_df.link)\n",
    "\n",
    "for link in link_games[0:15]:\n",
    "    try:\n",
    "        response=requests.get(link)\n",
    "        soup = BeautifulSoup(response.text, 'html5lib')\n",
    "        row1={}\n",
    "        row1['title']=soup.find('div', class_='apphub_AppName').text\n",
    "        for developers in soup.find_all('div', class_=\"summary column\", id=\"developers_list\"):\n",
    "            developer=[one_developer.text for one_developer in developers.find_all('a')]\n",
    "        row1['developer']=developer\n",
    "        user_tags=[tag.text.replace(\"\\n\",\"\").strip(\"\\t\") for tag in soup.find_all('a', class_=\"app_tag\")]\n",
    "        row1['user_tags']=user_tags\n",
    "        all_lang=[]\n",
    "        for languages in soup.find_all('table', class_=\"game_language_options\"):\n",
    "            for element in languages.find_all('tr', style=True, class_=True):\n",
    "                language=(element.find('td', class_=\"ellipsis\").text.replace(\"\\n\",\"\").strip(\"\\t\"))\n",
    "                options=[language if bool(options.text.replace(\"\\n\",\"\").strip(\"\\t\")) else 0 for options in element.find_all('td', class_=\"checkcol\")]\n",
    "                all_lang.append(tuple(options))\n",
    "        row1['languages']=all_lang\n",
    "        x=soup.find_all('div', class_=\"details_block\")[0].text.replace(\"\\n\",\"\").split(\"\\t\")\n",
    "        feature_list = list(filter(None, x))\n",
    "        y=feature_list[1].split(\":\")\n",
    "        genres=y[1]\n",
    "        row1['genres']=genres\n",
    "        specs=[]\n",
    "        for element in soup.find_all('div', class_=\"game_area_details_specs\"):\n",
    "            l=[]\n",
    "            for e2 in element.find_all('a'):\n",
    "                l.append(e2.text.replace(\"\\n\",\"\").strip(\"\\t\"))\n",
    "            specs.extend(l)\n",
    "        full_specs=list(filter(None, specs))\n",
    "        row1['specs']=full_specs \n",
    "        df_gamepg=df_gamepg.append(row1, ignore_index=True)\n",
    "    except:\n",
    "        print(link)\n",
    "df_gamepg.set_index('title', inplace=True)\n",
    "df_gamepg.rename(columns=lambda x: x.strip())\n",
    "pd.options.display.max_rows = 4000\n",
    "df_gamepg\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gamepg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_dup_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_dup_gamepg_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
