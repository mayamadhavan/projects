{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pair Problem\n",
    "\n",
    "Practice Lasso regularization technique in four steps on the given data set. Note there are functions (such as GridSearchCV) that will do a lot of the heavy lifting for you, but for the purpose of this pair don't use them -- we want you to implement cross-validation manually!\n",
    "\n",
    "Use the KFold function from sklearn to divide the data into 5 training/test sets.\n",
    "\n",
    "Tune the alpha parameter in the lasso model by looping over a grid of possible $\\alpha$s (sklearn: lasso)\n",
    "\n",
    "For each candidate $\\alpha$, loop over the 5 training/test sets.\n",
    "On each training/test set run the lasso model on the training set and then compute and record the prediction error in the test set.\n",
    "Finally total the prediction error for the 5 training/test sets.\n",
    "\n",
    "Set $\\alpha$ to be the value that minimizes prediction error.\n",
    "\n",
    "Run the lasso model again with the optimal $\\alpha$ determined in step 3. Which variables would you consider excluding on the basis of these results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Lasso_practice_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['y']\n",
    "X = df.drop(('y'), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n=len(X), n_folds=5, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = [10**x for x in range(-12, 5)]\n",
    "scores = np.zeros((len(alphas),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse for all alpha values \n",
      "\n",
      "           alpha              mse\n",
      "0   1.000000e-12  [1.01336924417]\n",
      "1   1.000000e-11  [1.01336924417]\n",
      "2   1.000000e-10  [1.01336924412]\n",
      "3   1.000000e-09  [1.01336924371]\n",
      "4   1.000000e-08  [1.01336923957]\n",
      "5   1.000000e-07  [1.01336919854]\n",
      "6   1.000000e-06  [1.01336878545]\n",
      "7   1.000000e-05   [1.0133646847]\n",
      "8   1.000000e-04  [1.01332383867]\n",
      "9   1.000000e-03  [1.01293200546]\n",
      "10  1.000000e-02  [1.01078287584]\n",
      "11  1.000000e-01  [1.08560564798]\n",
      "12  1.000000e+00  [5.20589356445]\n",
      "13  1.000000e+01  [14.1439768168]\n",
      "14  1.000000e+02  [14.1439768168]\n",
      "15  1.000000e+03  [14.1439768168]\n",
      "16  1.000000e+04  [14.1439768168]\n"
     ]
    }
   ],
   "source": [
    "for j in range(len(alphas)):\n",
    "    kf_score = []\n",
    "    for train, test in kf:\n",
    "        X_train = X.iloc[train]\n",
    "        y_train = y.iloc[train]\n",
    "        X_test = X.iloc[test]\n",
    "        y_test = y.iloc[test]\n",
    "        std_scaler = preprocessing.StandardScaler()\n",
    "        X_train_norm = std_scaler.fit_transform(X_train)\n",
    "        X_test_norm = std_scaler.transform(X_test)\n",
    "    \n",
    "        model =  Lasso(alpha = alphas[j])\n",
    "        model.fit(X_train_norm, y_train)\n",
    "        y_test_predict = model.predict(X_test_norm)\n",
    "        score = mean_squared_error(y_test_predict, y_test)\n",
    "        kf_score.append(score)\n",
    "    scores[j] = np.mean(kf_score)\n",
    "print ('mse for all alpha values \\n')\n",
    "print (pd.DataFrame(list(zip(alphas, scores)), columns=['alpha', 'mse']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best alpha is: 0.01\n"
     ]
    }
   ],
   "source": [
    "best_alpha = alphas[scores.argmin()]\n",
    "print ('best alpha is:', best_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE of final model is: 0.991396697544\n"
     ]
    }
   ],
   "source": [
    "std_scaler = preprocessing.StandardScaler()\n",
    "X_norm = std_scaler.fit_transform(X)\n",
    "\n",
    "final_model =  Lasso(alpha = best_alpha)\n",
    "final_model.fit(X_norm, y)\n",
    "y_predict = final_model.predict(X_norm)\n",
    "final_model_score = mean_squared_error(y_predict, y)\n",
    "print ('MSE of final model is:', final_model_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables we would like to retain are\n",
      "   variable  coefficient\n",
      "1        x2    -1.792169\n",
      "2        x3    -0.130112\n",
      "4        x5    -0.009247\n",
      "5        x6     1.844775\n",
      "7        x8     0.002409\n",
      "8        x9    -0.195843\n",
      "9       x10     0.173621\n",
      "11      x12    -0.007097\n",
      "13      x14    -2.224042\n",
      "14      x15     0.013011\n",
      "15      x16     1.019130\n",
      "16      x17     0.044092\n",
      "17      x18    -0.017809\n",
      "19      x20    -0.347023\n"
     ]
    }
   ],
   "source": [
    "df_coef = pd.DataFrame(list(zip(X.columns, final_model.coef_)), columns = ['variable', 'coefficient'])\n",
    "print ('Variables we would like to retain are')\n",
    "print (df_coef[df_coef['coefficient']!=0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables we would like to drop are\n",
      "   variable  coefficient\n",
      "0        x1         -0.0\n",
      "3        x4          0.0\n",
      "6        x7          0.0\n",
      "10      x11         -0.0\n",
      "12      x13         -0.0\n",
      "18      x19          0.0\n"
     ]
    }
   ],
   "source": [
    "print ('Variables we would like to drop are')\n",
    "print (df_coef[df_coef['coefficient']==0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
